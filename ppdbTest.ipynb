{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdb_dict = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationDict(dictIn):\n",
    "    '''\n",
    "    A class storing a dictionary of phrasal, lexical,\n",
    "    and syntactic transformations.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(TransformationDict, self).__init__()\n",
    "        self.index = {}\n",
    "    \n",
    "    def add(self, lhs, rhs):\n",
    "        temp = self\n",
    "        if len (lhs) == 0:\n",
    "            return\n",
    "        for i, token in enumerate(lhs):\n",
    "            if token in temp:\n",
    "                rule_list,temp= temp[token]\n",
    "            else:\n",
    "                rule_list = set()\n",
    "                new_temp = TransformationDict()\n",
    "                temp[token] = (rule_list, new_temp)\n",
    "                temp = new_temp\n",
    "            \n",
    "            if 0 < i < len(lhs)-1:\n",
    "                if token not in self.index:\n",
    "                    self.index[token] = set()\n",
    "                before = tuple(lhs[:i])\n",
    "                after = tuple(lhs[i+1:])\n",
    "                self.index[token].add((before,after))\n",
    "            \n",
    "        rule_list.add(rhs)\n",
    "    \n",
    "    def find_partial(self, partial):\n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import gc\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"Process a chunk of the file.\"\"\"\n",
    "    parsed_data = []\n",
    "    for line in chunk:\n",
    "        columns = line.strip().split('|||')\n",
    "        parsed_data.append(columns)\n",
    "    return parsed_data\n",
    "\n",
    "def read_in_chunks(file_object, chunk_size=1024*1024):\n",
    "    \"\"\"Lazy function to read a file piece by piece.\"\"\"\n",
    "    while True:\n",
    "        data = file_object.readlines(chunk_size)\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n",
    "\n",
    "def parse_file_parallel(file_path, chunk_size=1024*1024):\n",
    "    # Open the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read and process the file in chunks\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            # Submit each chunk to the executor\n",
    "            future_to_chunk = {executor.submit(process_chunk, chunk): chunk for chunk in read_in_chunks(file, chunk_size)}\n",
    "            # Combine results as they are completed\n",
    "            parsed_data = []\n",
    "            for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "                parsed_data.extend(future.result())\n",
    "                gc.collect()\n",
    "    return parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = parse_file_parallel(file, 512*512)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path, cursor):\n",
    "\n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the file line by line\n",
    "        \n",
    "        for line in file:\n",
    "            # Strip newline characters and split the line into columns\n",
    "            columns = line.strip().split('|||')\n",
    "            # Add the parsed columns to the parsed_data list\n",
    "            cursor.execute(\"INSERT INTO ppdb VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[NN] ', ' transplant ', ' transplantation ', ' PPDB2.0Score=5.24981 PPDB1.0Score=3.295900 -logp(LHS|e1)=0.18597 -logp(LHS|e2)=0.14031 -logp(e1|LHS)=11.83583 -logp(e1|e2)=1.80507 -logp(e1|e2,LHS)=1.46728 -logp(e2|LHS)=11.47593 -logp(e2|e1)=1.49083 -logp(e2|e1,LHS)=1.10738 AGigaSim=0.63439 Abstract=0 Adjacent=0 CharCountDiff=5 CharLogCR=0.40547 ContainsX=0 Equivalence=0.371472 Exclusion=0.000344 GlueRule=0 GoogleNgramSim=0.03067 Identity=0 Independent=0.078161 Lex(e1|e2)=9.64663 Lex(e2|e1)=59.48919 Lexical=1 LogCount=4.67283 MVLSASim=NA Monotonic=1 OtherRelated=0.372735 PhrasePenalty=1 RarityPenalty=0 ForwardEntailment=0.177287 SourceTerminalsButNoTarget=0 SourceWords=1 TargetComplexity=0.98821 TargetFormality=0.98464 TargetTerminalsButNoSource=0 TargetWords=1 UnalignedSource=0 UnalignedTarget=0 WordCountDiff=0 WordLenDiff=5.00000 WordLogCR=0 ', ' 0-0 ', ' OtherRelated']\n"
     ]
    }
   ],
   "source": [
    "file = 'ppdb-2.0-xxxl-all'\n",
    "data = parse_file(file)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def parse_file(file_path, startLine, endLine):\n",
    "    \"\"\"\n",
    "    Parse the file starting at startLine and ending at endLine.\n",
    "    \"\"\"\n",
    "    # Create an empty list to store the parsed data\n",
    "    parsed_data = []\n",
    "\n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the file line by line starting at line startLine\n",
    "        for line in itertools.islice(file, startLine, endLine):\n",
    "            # Strip newline characters and split the line into columns\n",
    "            columns = line.strip().split('|||')\n",
    "            # Add the parsed columns to the parsed_data list\n",
    "            parsed_data.append(columns)\n",
    "    \n",
    "    return parsed_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[NN] ', ' transplant ', ' transplantation ', ' PPDB2.0Score=5.24981 PPDB1.0Score=3.295900 -logp(LHS|e1)=0.18597 -logp(LHS|e2)=0.14031 -logp(e1|LHS)=11.83583 -logp(e1|e2)=1.80507 -logp(e1|e2,LHS)=1.46728 -logp(e2|LHS)=11.47593 -logp(e2|e1)=1.49083 -logp(e2|e1,LHS)=1.10738 AGigaSim=0.63439 Abstract=0 Adjacent=0 CharCountDiff=5 CharLogCR=0.40547 ContainsX=0 Equivalence=0.371472 Exclusion=0.000344 GlueRule=0 GoogleNgramSim=0.03067 Identity=0 Independent=0.078161 Lex(e1|e2)=9.64663 Lex(e2|e1)=59.48919 Lexical=1 LogCount=4.67283 MVLSASim=NA Monotonic=1 OtherRelated=0.372735 PhrasePenalty=1 RarityPenalty=0 ForwardEntailment=0.177287 SourceTerminalsButNoTarget=0 SourceWords=1 TargetComplexity=0.98821 TargetFormality=0.98464 TargetTerminalsButNoSource=0 TargetWords=1 UnalignedSource=0 UnalignedTarget=0 WordCountDiff=0 WordLenDiff=5.00000 WordLogCR=0 ', ' 0-0 ', ' OtherRelated']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhs</th>\n",
       "      <th>phrase</th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>features</th>\n",
       "      <th>alignment</th>\n",
       "      <th>entailment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[NN]</td>\n",
       "      <td>transplant</td>\n",
       "      <td>transplantation</td>\n",
       "      <td>PPDB2.0Score=5.24981 PPDB1.0Score=3.295900 -l...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>OtherRelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[JJ]</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>PPDB2.0Score=5.22098 PPDB1.0Score=9.463800 -l...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Equivalence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[JJ]</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>PPDB2.0Score=5.21828 PPDB1.0Score=9.463820 -l...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Equivalence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[JJ]</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>PPDB2.0Score=5.21462 PPDB1.0Score=9.463780 -l...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Equivalence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[JJ]</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>&lt;www.un.org/depts/dgacm/docs/crp/aconf212crp1...</td>\n",
       "      <td>PPDB2.0Score=5.21153 PPDB1.0Score=9.463800 -l...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Equivalence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>[NNS]</td>\n",
       "      <td>producers</td>\n",
       "      <td>implementers</td>\n",
       "      <td>PPDB2.0Score=3.20078 PPDB1.0Score=18.919140 -...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>[NNS]</td>\n",
       "      <td>developers</td>\n",
       "      <td>mobilizers</td>\n",
       "      <td>PPDB2.0Score=3.20078 PPDB1.0Score=16.644660 -...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>[NNS]</td>\n",
       "      <td>features</td>\n",
       "      <td>arguments</td>\n",
       "      <td>PPDB2.0Score=3.20078 PPDB1.0Score=24.431830 -...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>[NNS]</td>\n",
       "      <td>disagreements</td>\n",
       "      <td>referrals</td>\n",
       "      <td>PPDB2.0Score=3.20078 PPDB1.0Score=24.889380 -...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>[NNPS]</td>\n",
       "      <td>states</td>\n",
       "      <td>declares</td>\n",
       "      <td>PPDB2.0Score=3.20078 PPDB1.0Score=13.368920 -...</td>\n",
       "      <td>0-0</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lhs                                             phrase  \\\n",
       "0         [NN]                                         transplant    \n",
       "1         [JJ]    <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "2         [JJ]    <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "3         [JJ]    <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "4         [JJ]    <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "...         ...                                                ...   \n",
       "999995   [NNS]                                          producers    \n",
       "999996   [NNS]                                         developers    \n",
       "999997   [NNS]                                           features    \n",
       "999998   [NNS]                                      disagreements    \n",
       "999999  [NNPS]                                             states    \n",
       "\n",
       "                                               paraphrase  \\\n",
       "0                                        transplantation    \n",
       "1        <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "2        <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "3        <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "4        <www.un.org/depts/dgacm/docs/crp/aconf212crp1...   \n",
       "...                                                   ...   \n",
       "999995                                      implementers    \n",
       "999996                                        mobilizers    \n",
       "999997                                         arguments    \n",
       "999998                                         referrals    \n",
       "999999                                          declares    \n",
       "\n",
       "                                                 features alignment  \\\n",
       "0        PPDB2.0Score=5.24981 PPDB1.0Score=3.295900 -l...      0-0    \n",
       "1        PPDB2.0Score=5.22098 PPDB1.0Score=9.463800 -l...      0-0    \n",
       "2        PPDB2.0Score=5.21828 PPDB1.0Score=9.463820 -l...      0-0    \n",
       "3        PPDB2.0Score=5.21462 PPDB1.0Score=9.463780 -l...      0-0    \n",
       "4        PPDB2.0Score=5.21153 PPDB1.0Score=9.463800 -l...      0-0    \n",
       "...                                                   ...       ...   \n",
       "999995   PPDB2.0Score=3.20078 PPDB1.0Score=18.919140 -...      0-0    \n",
       "999996   PPDB2.0Score=3.20078 PPDB1.0Score=16.644660 -...      0-0    \n",
       "999997   PPDB2.0Score=3.20078 PPDB1.0Score=24.431830 -...      0-0    \n",
       "999998   PPDB2.0Score=3.20078 PPDB1.0Score=24.889380 -...      0-0    \n",
       "999999   PPDB2.0Score=3.20078 PPDB1.0Score=13.368920 -...      0-0    \n",
       "\n",
       "           entailment  \n",
       "0        OtherRelated  \n",
       "1         Equivalence  \n",
       "2         Equivalence  \n",
       "3         Equivalence  \n",
       "4         Equivalence  \n",
       "...               ...  \n",
       "999995    Independent  \n",
       "999996    Independent  \n",
       "999997    Independent  \n",
       "999998    Independent  \n",
       "999999    Independent  \n",
       "\n",
       "[1000000 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = 'ppdb-2.0-xxxl-all'\n",
    "data = parse_file(file,0,1000000)\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "# print(data[0])\n",
    "df = pd.DataFrame(data, columns=['lhs', 'phrase', 'paraphrase', 'features', 'alignment', 'entailment'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40138455\n"
     ]
    }
   ],
   "source": [
    "lineCount = 0\n",
    "with open(file, 'r') as f:\n",
    "    for line in f:\n",
    "        lineCount += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "138455\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "print(floor(lineCount/1000000))\n",
    "print(lineCount%1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, floor(lineCount/1000000)):\n",
    "    if i == 0:\n",
    "        data = parse_file(file, i*1000000, (i+1)*1000000)\n",
    "        df = pd.DataFrame(data, columns=['lhs', 'phrase', 'paraphrase', 'features', 'alignment', 'entailment'])\n",
    "    else:\n",
    "        data = parse_file(file, i*1000000, (i+1)*1000000)\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=['lhs', 'phrase', 'paraphrase', 'features', 'alignment', 'entailment'])], ignore_index=True)\n",
    "if lineCount%1000000 != 0:\n",
    "    data = parse_file(file, floor(lineCount/1000000)*1000000, lineCount)\n",
    "    df = pd.concat([df, pd.DataFrame(data, columns=['lhs', 'phrase', 'paraphrase', 'features', 'alignment', 'entailment'])], ignore_index=True)\n",
    "df.to_csv('ppdb-xxxl-all.csv')    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
